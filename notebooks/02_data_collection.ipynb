{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "650890a4",
   "metadata": {},
   "source": [
    "# Data Collection for Indian Election Sentiment Analysis\n",
    "**Author**: Lakshya Khetan  \n",
    "**Project**: Twitter Sentiment Analysis for Indian Elections\n",
    "\n",
    "This notebook demonstrates how to collect Twitter data using our modular data collection system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d5249",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "First, let's import the necessary modules and load our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0224d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data.collector import TwitterDataCollector\n",
    "from utils.config import ConfigManager\n",
    "from utils.logger import setup_logger\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac892c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_manager = ConfigManager('../config/config.yaml')\n",
    "config = config_manager.get_config()\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logger('data_collection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a90725",
   "metadata": {},
   "source": [
    "## Initialize Data Collector\n",
    "\n",
    "Create an instance of our Twitter data collector with the loaded configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5de6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Twitter data collector\n",
    "collector = TwitterDataCollector(config)\n",
    "\n",
    "print(\"Twitter Data Collector initialized successfully!\")\n",
    "print(f\"Configuration loaded: {len(config)} sections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cd96d0",
   "metadata": {},
   "source": [
    "## Collect Twitter Data\n",
    "\n",
    "Now let's collect some tweets related to Indian elections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cc063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search keywords for Indian elections\n",
    "keywords = [\n",
    "    'modi', 'bjp', 'congress', 'election2024', \n",
    "    'india election', 'indian politics', 'lokSabha'\n",
    "]\n",
    "\n",
    "# Collect tweets\n",
    "print(\"Starting data collection...\")\n",
    "tweets_df = collector.search_tweets(\n",
    "    keywords=keywords,\n",
    "    count=100,  # Collect 100 tweets\n",
    "    lang='en'   # English tweets only\n",
    ")\n",
    "\n",
    "print(f\"Collected {len(tweets_df)} tweets\")\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7768ea",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "Let's analyze the collected data to understand what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Total tweets: {len(tweets_df)}\")\n",
    "print(f\"Columns: {list(tweets_df.columns)}\")\n",
    "print(f\"Date range: {tweets_df['created_at'].min()} to {tweets_df['created_at'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample tweets\n",
    "print(\"Sample tweets:\")\n",
    "for i, row in tweets_df.head(5).iterrows():\n",
    "    print(f\"\\n{i+1}. {row['text'][:100]}...\")\n",
    "    print(f\"   Created: {row['created_at']}\")\n",
    "    print(f\"   User: {row['user']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a537a",
   "metadata": {},
   "source": [
    "## Data Filtering\n",
    "\n",
    "Apply filters to clean and refine our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7cd80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by language (if needed)\n",
    "collector.filter_by_language('en')\n",
    "\n",
    "# Get updated statistics\n",
    "stats = collector.get_data_stats()\n",
    "print(\"Filtered Dataset Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6299bfd",
   "metadata": {},
   "source": [
    "## Save Collected Data\n",
    "\n",
    "Save the collected tweets for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95460ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_file = '../data/collected_tweets.csv'\n",
    "success = collector.save_data(output_file, format='csv')\n",
    "\n",
    "if success:\n",
    "    print(f\"✅ Data successfully saved to {output_file}\")\n",
    "    print(f\"File size: {os.path.getsize(output_file)} bytes\")\n",
    "else:\n",
    "    print(\"❌ Failed to save data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5991b",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The collected data is now ready for preprocessing. The next notebook will demonstrate:\n",
    "\n",
    "1. **Text Preprocessing** - Cleaning and preparing the tweet text\n",
    "2. **Tokenization** - Converting text to numerical sequences\n",
    "3. **Data Validation** - Ensuring data quality\n",
    "\n",
    "Navigate to `03_data_preprocessing.ipynb` to continue the workflow."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
