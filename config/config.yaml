# Configuration file for Twitter Sentiment Analysis - Lakshya Khetan
# This file contains all project settings and parameters

# Twitter API Configuration
twitter:
  consumer_key: ${TWITTER_CONSUMER_KEY}
  consumer_secret: ${TWITTER_CONSUMER_SECRET}
  access_token: ${TWITTER_ACCESS_TOKEN}
  access_token_secret: ${TWITTER_ACCESS_TOKEN_SECRET}
  
# Data Collection Settings
data_collection:
  keywords:
    bjp: "#BJP OR #Modi OR #AmitShah OR #BhartiyaJantaParty"
    congress: "#IndianNationalCongress OR #RahulGandhi OR #SoniaGandhi OR #INC"
  
  search_params:
    count: 200
    include_rts: false
    lang: "en"
    pages: 50
    result_type: "recent"
  
  date_range:
    start_date: "2019-01-01"
    end_date: "2019-04-30"

# Data Preprocessing Settings
preprocessing:
  text_cleaning:
    remove_urls: true
    remove_mentions: true
    remove_hashtags: false
    remove_rt: true
    remove_emojis: true
    remove_punctuation: true
    convert_lowercase: true
    remove_stopwords: true
    min_word_length: 2
  
  tokenization:
    max_features: 10000
    max_sequence_length: 1000
    oov_token: "<OOV>"
  
  sentiment_labeling:
    method: "textblob"  # textblob, vader, or manual
    threshold: 0.0  # polarity threshold for positive/negative classification

# Model Configuration
models:
  glove:
    embedding_dim: 100
    embedding_file: "glove/glove.6B.100d.txt"
    trainable: false
    max_features: 10000
    sequence_length: 1000
    
    architecture:
      dense_layers: [100, 50, 50]
      dropout_rate: 0.5
      activation: "relu"
      final_activation: "sigmoid"
      l2_regularization: 0.002
    
    training:
      optimizer: "adam"
      learning_rate: 0.0001
      loss: "binary_crossentropy"
      metrics: ["accuracy"]
      batch_size: 1024
      epochs: 10
      validation_split: 0.2
      early_stopping: true
      patience: 3

  lstm:
    embedding_dim: 128
    lstm_units: 64
    sequence_length: 1000
    max_features: 10000
    
    architecture:
      bidirectional: true
      dropout: 0.3
      recurrent_dropout: 0.3
      dense_layers: [64, 32]
      final_activation: "sigmoid"
    
    training:
      optimizer: "adam"
      learning_rate: 0.001
      loss: "binary_crossentropy"
      metrics: ["accuracy"]
      batch_size: 32
      epochs: 20
      validation_split: 0.2
      early_stopping: true
      patience: 5

# File Paths
paths:
  data:
    raw: "data/raw/"
    processed: "data/processed/"
    interim: "data/interim/"
    external: "data/external/"
  
  models:
    saved: "models/saved/"
    checkpoints: "models/checkpoints/"
  
  results:
    figures: "results/figures/"
    reports: "results/reports/"
    predictions: "results/predictions/"
  
  logs: "logs/"

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/twitter_sentiment.log"
  console: true

# Visualization Settings
visualization:
  figure_size: [12, 8]
  dpi: 300
  style: "seaborn"
  color_palette: "Set2"
  font_size: 12
  save_format: "png"

# Evaluation Settings
evaluation:
  metrics: ["accuracy", "precision", "recall", "f1_score", "auc"]
  cross_validation:
    enabled: true
    folds: 5
    stratify: true
  
  test_size: 0.2
  random_state: 42

# Production Settings
production:
  model_serving:
    host: "0.0.0.0"
    port: 8000
    workers: 4
  
  batch_prediction:
    batch_size: 1000
    output_format: "json"
  
  monitoring:
    log_predictions: true
    performance_threshold: 0.85